{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OPENSLIDE along with necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENSLIDE_PATH = r'C:\\Users\\80027294\\Documents\\openslide-bin-4.0.0.3-windows-x64\\openslide-bin-4.0.0.3-windows-x64\\bin'\n",
    "\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    # Windows\n",
    "    with os.add_dll_directory(OPENSLIDE_PATH):\n",
    "        import openslide\n",
    "        print(\"Imported openslide - from new path\")\n",
    "else:\n",
    "    import openslide\n",
    "import torch\n",
    "import argparse\n",
    "#import os\n",
    "import sys\n",
    "import numpy as np\n",
    "#import openslide\n",
    "sys.path.append('../path-data-processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create Binary Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image(image):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        transforms.Lambda(lambda t: torch.minimum(torch.tensor([1]), t)),\n",
    "        transforms.Lambda(lambda t: torch.maximum(torch.tensor([0]), t)),\n",
    "        transforms.ToPILImage(),\n",
    "    ])\n",
    "    # plt.imsave('test_inference.jpg',reverse_transforms(image[0]))\n",
    "    return reverse_transforms(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that finds contours from our binary mask and then creates an XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_from_binary_mask(binary_mask, xml_file_path, microns_per_pixel=0.494200):\n",
    "    # Threshold the image to obtain a binary mask\n",
    "    _, binary_image = cv2.threshold(binary_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create the root element\n",
    "    root = ET.Element(\"Annotations\")\n",
    "\n",
    "    # Iterate through each contour and create corresponding XML elements\n",
    "    for i, contour in enumerate(contours):\n",
    "        object_elem = ET.SubElement(root, \"Object\")\n",
    "        ET.SubElement(object_elem, \"ID\").text = str(i)\n",
    "        \n",
    "        for point in contour:\n",
    "            point_elem = ET.SubElement(object_elem, \"Point\")\n",
    "            ET.SubElement(point_elem, \"X\").text = str(point[0][0])\n",
    "            ET.SubElement(point_elem, \"Y\").text = str(point[0][1])\n",
    "\n",
    "    # Create the XML tree\n",
    "    tree = ET.ElementTree(root)\n",
    "\n",
    "    # Write the XML to a file\n",
    "    tree.write(xml_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create XML Structure for Detected Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml(contours):\n",
    "    # Create the root element with MicronsPerPixel attribute\n",
    "    root = ET.Element(\"Annotations\", MicronsPerPixel=\"0.494200\")\n",
    "    \n",
    "    # Iterate through each contour and create corresponding XML elements\n",
    "    for i, contour in enumerate(contours):\n",
    "        annotation_elem = ET.SubElement(root, \"Annotation\", Id=str(i+1), Name=\"\", ReadOnly=\"0\", NameReadOnly=\"0\", \n",
    "                                        LineColorReadOnly=\"0\", Incremental=\"0\", Type=\"4\", LineColor=\"65280\", \n",
    "                                        Visible=\"1\", Selected=\"1\", MarkupImagePath=\"\", MacroName=\"\")\n",
    "        \n",
    "        ET.SubElement(annotation_elem, \"Attributes\")\n",
    "        regions_elem = ET.SubElement(annotation_elem, \"Regions\")\n",
    "        ET.SubElement(regions_elem, \"RegionAttributeHeaders\")\n",
    "        \n",
    "        # Assuming length and area calculations for the Region element\n",
    "        length = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        region_elem = ET.SubElement(regions_elem, \"Region\", Id=str(i+1), Type=\"0\", Zoom=\"0.450000\", Selected=\"0\", \n",
    "                                    ImageLocation=\"\", ImageFocus=\"-1\", Length=str(length), Area=str(area), \n",
    "                                    LengthMicrons=str(length * 0.494200), AreaMicrons=str(area * (0.494200**2)), \n",
    "                                    Text=\"\", NegativeROA=\"0\", InputRegionId=\"0\", Analyze=\"1\", DisplayId=str(i+1))\n",
    "        \n",
    "        ET.SubElement(region_elem, \"Attributes\")\n",
    "        vertices_elem = ET.SubElement(region_elem, \"Vertices\")\n",
    "        \n",
    "        for point in contour:\n",
    "            ET.SubElement(vertices_elem, \"Vertex\", X=str(point[0][0]), Y=str(point[0][1]), Z=\"0\")\n",
    "    \n",
    "    return ET.ElementTree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function with 3 parameters:\n",
    "\n",
    "Scale: The resolution we want the original image to be resized to during inference\n",
    "\n",
    "Checkpoint: The .pth file that contains our optimized weights so that we can calculate an inference when our image goes through the model\n",
    "\n",
    "wsi_dir: The directory that contains our WSI images we want to use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(wsi_dir,checkpoint,scale):\n",
    "    #First preprocess data\n",
    "    os.makedirs(f'outputs/{wsi_dir.split(\"/\")[1][:-4]}',exist_ok=True)\n",
    "    transforms_test = transforms.Compose([\n",
    "        transforms.Resize(240,interpolation=InterpolationMode.BILINEAR, max_size=None),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    # Load UNet model\n",
    "    model = UNet(in_channels=3, num_classes=1)\n",
    "    checkpoint1 = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint1)\n",
    "    model.eval()\n",
    "\n",
    "    inp_path = wsi_dir\n",
    "    slide = openslide.open_slide(inp_path)\n",
    "    tiles = DeepZoomGenerator(slide, tile_size=256, overlap=0, limit_bounds=False)\n",
    "    print(f\"WSI Dimensions: {slide.dimensions}\")\n",
    "\n",
    "    max_dim = len(tiles.level_tiles)\n",
    "    cols, rows = tiles.level_tiles[max_dim-1]   \n",
    "    tile_count = 0 \n",
    "    unused = []\n",
    "    restitch = np.zeros(slide.dimensions)\n",
    "    # Take WSI and process into patches\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            tile_name = str(row) + \"_\" + str(col)\n",
    "            # my_conv = \n",
    "            # pdb.set_trace()\n",
    "            temp_tile = tiles.get_tile(max_dim-1, (col, row))\n",
    "            temp_tile_RGB = temp_tile.convert('RGB')\n",
    "            temp_tile_np = np.array(temp_tile_RGB)\n",
    "            #Save original tile\n",
    "\n",
    "            if (temp_tile_np.mean() < 235 and temp_tile_np.std() > 15):\n",
    "                # import pdb; pdb.set_trace()\n",
    "                print(\"Processing tile number:\", tile_name)\n",
    "                img = Image.fromarray(temp_tile_np)\n",
    "                image = transforms_test(img)\n",
    "        # image=image.unsqueeze(0).to(device='cuda')\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # import pdb; pdb.set_trace()\n",
    "                    outs = model(image.unsqueeze(0))\n",
    "                \n",
    "                pred = show_tensor_image(outs)   \n",
    "                # import pdb; pdb.set_trace()\n",
    "                restitch[row*256:row*256+256,col*256:col*256+256] = cv2.resize(np.array(pred),(256,256),interpolation = cv2.INTER_LINEAR) if restitch[row*256:row*256+256,col*256:col*256+256].shape == (256,256) else pred\n",
    "                #tifffile giving weird bugs so i use imageio\n",
    "                # restitch[row*256:row*256+256,col*256:col*256+256] = torch.nn.functional.interpolate(predictions.unsqueeze(0),restitch[row*256:row*256+256,col*256:col*256+256].shape,mode='bilinear').squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "                # temp_tile_np -> to model\n",
    "            else:\n",
    "                \n",
    "                print(\"NOT PROCESSING TILE:\", tile_name)\n",
    "                \n",
    "                # pdb.set_trace()\n",
    "                \n",
    "\n",
    "            tile_count+=1\n",
    "    # print(f\"Step 3/3: Making GT patches\")\n",
    "    thumbnail = slide.get_thumbnail(slide.level_dimensions[-1])\n",
    "    thumbnail = np.array(thumbnail)\n",
    "    # Resize the mask to match the thumbnail's size\n",
    "    # resized_mask = cv2.resize(mask, thumbnail.shape[1::-1], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    restitch = restitch.astype(np.uint8)\n",
    "    # Apply the mask to the thumbnail image\n",
    "    # import pdb; pdb.set_trace()\n",
    "    new_h = int(restitch.shape[0]/scale)\n",
    "    new_w = int(restitch.shape[1]/scale)\n",
    "    masked_image = cv2.bitwise_and(thumbnail, thumbnail, mask=restitch)\n",
    "    # Save the probabilities \n",
    "    plt.imsave(f'outputs/{wsi_dir.split(\"/\")[1][:-4]}/test_inference.jpg',cv2.resize(restitch,(new_h,new_w),interpolation = cv2.INTER_LINEAR))\n",
    "    # Save the bitwiseAND mask\n",
    "    plt.imsave(f'outputs/{wsi_dir.split(\"/\")[1][:-4]}/masked_wsi.jpg',cv2.resize(masked_image,(new_h,new_w),interpolation = cv2.INTER_LINEAR))\n",
    "    print(f\"***Processed Slide***\")\n",
    "\n",
    "    #yellow: r: 255, g: 255, b: 0\n",
    "\n",
    "    # Threshold the image to obtain a binary mask\n",
    "    _, binary_image = cv2.threshold(restitch, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    # Create XML that passes in approximate contours\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # np.stack([np.zeros((2800,2800)),restitch,restitch])\n",
    "    # xml_file_path = \"binary_mask.xml\"\n",
    "    # create_xml_from_binary_mask(restitch, xml_file_path)\n",
    "\n",
    "    # Create the new XML structure\n",
    "    # This wil create XML file \n",
    "    new_xml_tree = create_xml(contours)\n",
    "\n",
    "    # Save the new XML file\n",
    "    new_xml_path = f'outputs/{wsi_dir.split(\"/\")[1][:-4]}/new_annotations.xml'\n",
    "    new_xml_tree.write(new_xml_path)\n",
    "\n",
    "    # Print the path of the generated XML file\n",
    "    print(f'XML file saved at: {new_xml_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGE THE FOLLOWING PARAMETERS TO SEE INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_dir=''\n",
    "checkpoint=''\n",
    "scale=''\n",
    "main(wsi_dir,checkpoint,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML annotations, inference, and bitwiseAND files saved in outputs folder "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tls-wsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
